# ğŸ–ï¸ Hand Sign Detection Using Python

This project is a real-time **hand sign detection system** built using **MediaPipe**, **OpenCV**, and **TensorFlow**.  
It detects specific hand signs and converts them to **text** and **speech output**.  
The goal is to bridge communication gaps by translating hand gestures into understandable words.

---

## ğŸš€ Features

- ğŸ¥ **Real-time** hand sign detection via webcam  
- ğŸ§  **Gesture recognition** powered by trained TensorFlow models  
- ğŸ—£ï¸ **Text-to-Speech output** using pyttsx3 or gTTS  
- ğŸ’» Lightweight Python script, easy to run  
- ğŸ–ï¸ Hand tracking using OpenCV + MediaPipe

---

## ğŸ› ï¸ Technologies Used

| ğŸ”§ Tech        | ğŸ’¡ Description                             |
|---------------|---------------------------------------------|
| ğŸ **Python**     | Core programming language                |
| ğŸª **MediaPipe**  | Hand landmark detection and tracking     |
| ğŸï¸ **OpenCV**     | Image processing & webcam capture        |
| ğŸ§  **TensorFlow** | ML model to recognize hand signs         |
| ğŸ”Š **pyttsx3** / ğŸ”ˆ **gTTS** | Converts predicted text to speech       |

---

ğŸ”— **GitHub:**  
ğŸ‘‰ [https://github.com/rohinicc/hand_sign](https://github.com/rohinicc/hand_sign)

---

## âœ… Quick Setup Instructions (ALL-IN-ONE TERMINAL CODE)

Copy-paste this entire block into your terminal and you're ready to roll:

```bash
# ğŸš€ Clone the project
git clone https://github.com/rohinicc/hand_sign.git
cd hand_sign

# ğŸ›¡ï¸ (Optional) Create and activate a virtual environment
python -m venv venv

# â–¶ï¸ For Windows
venv\Scripts\activate

# â–¶ï¸ For macOS/Linux
# source venv/bin/activate

# ğŸ“¦ Install required packages
pip install opencv-python
pip install mediapipe
pip install tensorflow
pip install numpy
pip install pyttsx3

# ğŸ” Optional: If pyttsx3 doesn't work for TTS, use gTTS instead
pip install gTTS playsound

# ğŸ¯ Run the main script
python testvoice.py
